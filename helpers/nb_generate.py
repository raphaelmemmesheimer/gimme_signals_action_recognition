
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: ../generate_representations.ipynb

# %matplotlib inline
# %matplotlib widget
import scipy.io as sio
import math
import numpy as np
import time
import os
import zipfile
import pickle
import urllib.request
import matplotlib
import matplotlib.pyplot as plt
import cv2

from matplotlib import animation, rc
from IPython.display import HTML
import pandas as pd
from mpl_toolkits.mplot3d import Axes3D
import helpers.read_skeleton
import helpers.skeleton_helpers
from helpers.skeleton_helpers import SkeletonAnimation, SignalAnimation, SkeletonSignalAnimation
from tqdm.auto import tqdm
# import visdom
# import pyts
# from pyts.multivariate.image import JointRecurrencePlot

matplotlib.rcParams['axes.spines.left'] = False
matplotlib.rcParams['axes.spines.right'] = False
matplotlib.rcParams['axes.spines.top'] = False
matplotlib.rcParams['axes.spines.bottom'] = False

def filter_skeleton(skeleton_data):
    # filter foot # no infomration worth there and the estimates are very noisy
    filtered_skeleton = skeleton_data
    filtered_skeleton[15] = filtered_skeleton[14]
    filtered_skeleton[19] = filtered_skeleton[18]
    return filtered_skeleton

def filter_attention(skeleton_data, filter_percentage):
    dtype = [('index', int), ('var', float), ('std', float)]
    filtered_skeleton = skeleton_data
    values = []
    for i, col in enumerate(skeleton_data):
        values.append((i, col.var(), col.std()))
    a = np.array(values, dtype=dtype)
    a = np.sort(a, order='std')
    to_remove = []
    for i, dic in enumerate(a[::-1]):
        if i > len(a) * (1-filter_percentage):
            break
        to_remove.append(dic[0])
    for x in to_remove:
        filtered_skeleton[x] = np.zeros(filtered_skeleton[x].shape)
    return filtered_skeleton


def get_experiment_string(skeleton_data, size=5, offset=False, approach_id=1, alpha=0.2, attention=False, filter_percentage=0.2):
    if approach_id == 11:
        experiment_string = "approach_id"+str(approach_id).zfill(3)+"_gradient_alpha_size_"+str(size)+("_attention" if attention else "_no_attention")+"_filter_"+str(filter_percentage).zfill(2)
    else:
        experiment_string = "approach_id"+str(approach_id).zfill(3)+"_"+str(alpha)+"_size_"+str(size)+("_attention" if attention else "_no_attention")+"_filter_"+str(filter_percentage).zfill(2)
    return experiment_string



def plot_skeleton_data(skeleton_data, size=5, offset=False, approach_id=1, alpha=0.2, attention=False, filter_percentage=0.2):
    fig = plt.figure(figsize=(5,5))
#   fig.title(filename)
    ax = fig.add_subplot(frameon=False)
#     ax = fig.add_axes([0, 0, 1, 1])
    ax.axis("off")
    fig.tight_layout(pad=0)
    # To remove the huge white borders
    ax.margins(0)
#     ax = plt.figure(frameon=False)
#     ax.spines['top'].set_visible(False)
#     ax.spines['right'].set_visible(False)
#     ax.spines['bottom'].set_linewidth(0.0)
#     ax.spines['left'].set_linewidth(0.0)
#     plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)



    if approach_id == 3:
        skeleton_data = np.sort(skeleton_data, axis=0)

    if approach_id == 8:
        skeleton_data = filter_skeleton(skeleton_data)

    if approach_id == 9:
        print("before filter, ",skeleton_data.shape)
        skeleton_data = filter_attention(skeleton_data)
        print("after filter, ",skeleton_data.shape)

    if attention:
        print("before filter, ",skeleton_data.shape)
        skeleton_data = filter_attention(skeleton_data, filter_percentage)
        print("after filter, ",skeleton_data.shape)

    for joint_index, joint_data in enumerate(skeleton_data):
        # line currently the best results
        color_offset = len(joint_data)
        if approach_id ==1:
            of1 = 0
            of2 = 2
            of3 = 3
        if approach_id ==2:
            of1=joint_index/2+offset
            of2=joint_index/2+offset
            of3=joint_index/2+offset
        if approach_id ==3:
            of1=joint_index/2+offset
            of2=joint_index/2+offset
            of3=joint_index/2+offset

            if joint_index > len(skeleton_data) / 6:
                continue
        if approach_id == 4:
            of1 = joint_index/2
            of2 = joint_index/2
            of3 = joint_index/2
            if joint_data.var() > 1:
                continue
        if approach_id == 5:
            import pyts
            from pyts.image import GramianAngularField
            transformer = GramianAngularField(image_size=len(joint_data))
            image_data = transformer.fit_transform(joint_data)
            plt.figure(figsize=(10,10))
            plt.imshow(image_data)
            plt.savefig("gaf.png")
            continue
        if approach_id == 6:
            of1 = -np.average(joint_data[0])
            of2 = -np.average(joint_data[1])
            of3 = -np.average(joint_data[2])
        if approach_id == 7:
            of1 = - np.max(joint_data[0])
            of2 = - np.max(joint_data[1])
            of3 = - np.max(joint_data[2])
        if approach_id == 8:
            of1 = - np.max(joint_data[0])
            of2 = - np.max(joint_data[1])
            of3 = - np.max(joint_data[2])
        if approach_id == 9:
            of1 = - np.max(joint_data[0])
            of2 = - np.max(joint_data[1])
            of3 = - np.max(joint_data[2])
        if approach_id == 10:
            of1 = -np.average(joint_data[0])
            of2 = -np.average(joint_data[1])+0.5
            of3 = -np.average(joint_data[2])+1
        if approach_id == 11: # like 10 but use alpha for temporal
            of1 = -np.average(joint_data[0])
            of2 = -np.average(joint_data[1])+0.5
            of3 = -np.average(joint_data[2])+1
            n = len(joint_data[0])
            s = 5 # Segment length
            alpha = 0.1
            for i in range(0,n-s,s):

                alpha = min(alpha+ (s / n), 1.0)
#                 print(alpha)

                ax.plot(range(i,i+s+1), of1+joint_data[0][i:i+s+1],  "-", linewidth=size, c=color_map[joint_index], alpha=alpha);
                ax.plot(range(i,i+s+1), of2+joint_data[1][i:i+s+1], "-", linewidth=size, c=color_map[color_offset+joint_index], alpha=alpha);
                ax.plot(range(i,i+s+1), of3+joint_data[2][i:i+s+1], "-", linewidth=size, c=color_map[2*color_offset+joint_index], alpha=alpha);
        else:
            try:
                ax.plot(range(len(joint_data[0])), of1+joint_data[0],  "-", linewidth=size, c=color_map[joint_index], alpha=alpha);
                ax.plot(range(len(joint_data[1])), of2+joint_data[1], "-", linewidth=size, c=color_map[color_offset+joint_index], alpha=alpha);
                ax.plot(range(len(joint_data[2])), of3+joint_data[2], "-", linewidth=size, c=color_map[2*color_offset+joint_index], alpha=alpha);
            except Exception as e:
                print(e)
#         ax.view_init(0, 0)

    return fig

def get_utd_mhad_dataset(modality=None):
    "`modaltiy` could be either `interial` oder `skeleton`"
    if modality == "inertial":
        dataset_name = "UTDMHAD_inertial"
        input_dataset_folder = os.environ["DATASET_FOLDER"]+"/utdmhad/Inertial/"
        dataset_folder = os.environ["DATASET_FOLDER"]+"/utdmhad/"+dataset_name
        color_map = helpers.skeleton_helpers.generate_color_map(7)
    if modality == "skeleton":
        dataset_name = "UTDMHAD_skeleton"
        input_dataset_folder = os.environ["DATASET_FOLDER"]+"/utdmhad/Skeleton/"
        dataset_folder = os.environ["DATASET_FOLDER"]+"/utdmhad/"+dataset_name
        color_map = helpers.skeleton_helpers.generate_color_map(22*3) # 20 joints / 3 signals per joint
    return dataset_name, input_dataset_folder, dataset_folder, color_map

def extract_utdmhad_skeleton(dataset_name, input_dataset_folder, dataset_folder, color_map, approach_id, attention=False, max_show=99999, save_svg=False,animate=False):
    "returns (str) target generated representation folder"
    #### os.path
    train_subjects = helpers.skeleton_helpers.get_utdmhad_train_subjects()

    directory = os.fsencode(input_dataset_folder)

    files = sorted(os.listdir(directory))
    experiment_str = ""
    for i, file in tqdm(enumerate(files), total=len(files)):
        filename = os.fsdecode(file)
#         print(str(i)+"/"+str(len(files)), filename[:3])
        if filename.endswith(".mat"):# and filename[:3] == "a1_":
            data = sio.loadmat(input_dataset_folder+"/"+filename)

            skeleton_data = data["d_skel"]
#             print("Selected"+str(len(files)), filename, skeleton_data.shape)
            if i > max_show:
                break
            class_name = filename[:filename.find("_")]
            subject = filename[filename.find("_")+1:filename.find("_")+3]
            set_cat = "train" if subject in train_subjects else "test"



            experiment_str = get_experiment_string(skeleton_data, size=1, approach_id=approach_id, attention=attention)
            fig = plot_skeleton_data(skeleton_data, size=1, approach_id=approach_id, attention=attention)#, offset=skeleton_data.var(), approach_id=2,size=2)


            dest_folder = dataset_folder+experiment_str+"/"+set_cat+"/"+class_name
            if not os.path.exists(dest_folder):
                os.makedirs(dest_folder, exist_ok=True)
#             print(class_name, subject, set_cat)

    #         jrp = JointRecurrencePlot(threshold='point', percentage=30)
    #         X_jrp = jrp.fit_transform(skeleton_data)
    #         plt.figure(figsize=(6, 6))
    #         plt.axis("off")
    #         plt.imshow(X_jrp[0], cmap='binary', origin='lower')
    #         plt.savefig(dest_folder+"/"+filename+".png")
    #         plt.close()
    #         fig.canvas.print_png(dest_folder+"/"+filename+"___canvas.png")
            dest_filename = dest_folder+"/"+filename+".png"
#             print(dest_filename)

            fig.savefig(dest_filename)
            if save_svg:
                dest_folder_svg = "exported_svg/"+dest_folder+""
                if not os.path.exists(dest_folder_svg):
                    os.makedirs(dest_folder_svg, exist_ok=True)
                dest_filename_svg = dest_folder_svg+"/"+filename+".svg"
                print("Saving_svg ",dest_filename_svg)
                fig.savefig(dest_filename_svg)
            if animate:
                a = SignalAnimation(skeleton_data.transpose(), clear_frames=True)
                dest_folder_video = "exported_video/"+dest_folder+""
                if not os.path.exists(dest_folder_video):
                    os.makedirs(dest_folder_video, exist_ok=True)
                dest_filename_video = dest_folder_video+"/"+filename+".mp4"
                print("Saving_video ",dest_filename_video)
                a.save_as_mp4(dest_filename_video)
            if max_show > 26:
                plt.close()
        #         pickle.dump(fig, open(class_name+"/"+filename+".pkl", 'wb'))
    #
    return experiment_str
    # fig.show()

def extract_utdmhad_imu(dataset_name, input_dataset_folder, dataset_folder, color_map, max_show=999999, save_svg=False, animate=False):

    train_subjects = helpers.skeleton_helpers.get_utdmhad_train_subjects()


    files = helpers.skeleton_helpers.get_sorted_files_in_folder(input_dataset_folder)
#     directory = os.fsencode(dataset_folder)
#     files = sorted(os.listdir(directory))
    for i, file in tqdm(enumerate(files), total=len(files)):
        filename = os.fsdecode(file)
        print(str(i)+"/"+str(len(files)), filename[:3])
        if filename.endswith(".mat"):# and filename[:3] == "a1_":
            data = sio.loadmat(input_dataset_folder+"/"+filename)

            inertial_data = data["d_iner"].transpose()

            if i > max_show:
                break

            class_name = filename[:filename.find("_")]
            subject = filename[filename.find("_")+1:filename.find("_")+3]
            set_cat = "train" if subject in train_subjects else "test"
            dest_folder = dataset_folder+"/"+set_cat+"/"+class_name
            print("Selected"+str(len(files)), filename, dest_folder)
            if not os.path.exists(dest_folder):
                os.makedirs(dest_folder, exist_ok=True)

            fig = plot_skeleton_data(inertial_data)
            fig.savefig(dest_folder+"/"+filename+".png")
            if save_svg:
                dest_folder_svg = "exported_svg/"+dest_folder+""
                if not os.path.exists(dest_folder_svg):
                    os.makedirs(dest_folder_svg, exist_ok=True)
                dest_filename_svg = dest_folder_svg+"/"+filename+".svg"
                print("Saving_svg ",dest_filename_svg)
                fig.savefig(dest_filename_svg)
            if animate:
                a = SignalAnimation(inertial_data, clear_frames=True)
                dest_folder_video = "exported_video/"+dest_folder+""
                if not os.path.exists(dest_folder_video):
                    os.makedirs(dest_folder_video, exist_ok=True)
                dest_filename_video = dest_folder_video+"/"+filename+".mp4"
                print("Saving_video ",dest_filename_video)
                a.save_as_mp4(dest_filename_video)

            if max_show > 26:
                plt.close()

color_map = helpers.skeleton_helpers.generate_color_map(22*3+6) # 20 joints / 3 signals per joint + 6 from imu
def extract_utdmhad_fused(input_dataset_folder_skeleton, input_dataset_folder_inertial, dataset_folder, approach_id, attention=False, max_show=99999, save_svg=False):
    #### os.path
    print(input_dataset_folder_skeleton)
    print(input_dataset_folder_inertial)
    train_subjects = helpers.skeleton_helpers.get_utdmhad_train_subjects()

    directory = os.fsencode(input_dataset_folder_skeleton)

    files_skeleton = sorted(os.listdir(directory))

    for i, file in tqdm(enumerate(files_skeleton), total=len(files_skeleton)):
        filename = os.fsdecode(file)
        print(str(i)+"/"+str(len(files_skeleton)), filename[:3])
        if filename.endswith(".mat"):# and filename[:3] == "a1_":
            data_skeleton = sio.loadmat(input_dataset_folder_skeleton+"/"+filename)
            data_inertial = sio.loadmat(input_dataset_folder_inertial+"/"+filename[:-12]+"inertial.mat")
            skeleton_data = data_skeleton["d_skel"].transpose()
            inertial_data = data_inertial["d_iner"]
            inertial_data /= inertial_data.max()
            inertial_data = np.expand_dims(inertial_data, axis=1)
            print(skeleton_data.shape, inertial_data.shape, len(skeleton_data))


#             samples = []
            samples = np.sort(np.random.randint(0, len(inertial_data), len(skeleton_data)))
            print(samples)
#             sampled_inerial = np.delete(inertial_data, samples, axis=0)
            sampled_inerial = np.take(inertial_data, samples, axis=0)
            sampled_inerial = np.repeat(sampled_inerial[:, :, :], 3, axis=1)
#             sampled_inerial = np.repeat(sampled_inerial[:, :, :], 3, axis=2)
            print(skeleton_data.shape, inertial_data.shape, sampled_inerial.shape, len(skeleton_data))


            skeleton_data = np.concatenate((skeleton_data, sampled_inerial), axis=2).transpose()
            print("Selected"+str(len(files_skeleton)), filename, skeleton_data.shape)
            if i > max_show:
                break
            class_name = filename[:filename.find("_")]
            subject = filename[filename.find("_")+1:filename.find("_")+3]
            set_cat = "train" if subject in train_subjects else "test"


            experiment_str = get_experiment_string(skeleton_data, size=1, approach_id=approach_id, attention=attention)
            fig = plot_skeleton_data(skeleton_data, size=1, approach_id=approach_id, attention=attention, alpha=1.0)#, offset=skeleton_data.var(), approach_id=2,size=2)


            dest_folder = dataset_folder+experiment_str+"/"+set_cat+"/"+class_name
            if not os.path.exists(dest_folder):
                os.makedirs(dest_folder, exist_ok=True)
            print(class_name, subject, set_cat)

    #         jrp = JointRecurrencePlot(threshold='point', percentage=30)
    #         X_jrp = jrp.fit_transform(skeleton_data)
    #         plt.figure(figsize=(6, 6))
    #         plt.axis("off")
    #         plt.imshow(X_jrp[0], cmap='binary', origin='lower')
    #         plt.savefig(dest_folder+"/"+filename+".png")
    #         plt.close()
    #         fig.canvas.print_png(dest_folder+"/"+filename+"___canvas.png")
            dest_filename = dest_folder+"/"+filename+".png"
            print(dest_filename)
            fig.savefig(dest_filename)
            if save_svg:
                dest_folder_svg = "exported_svg/"+dest_folder+""
                if not os.path.exists(dest_folder_svg):
                    os.makedirs(dest_folder_svg, exist_ok=True)
                dest_filename_svg = dest_folder_svg+"/"+filename+".svg"
                print("Saving_svg ",dest_filename_svg)
                fig.savefig(dest_filename_svg)
            if max_show > 26:
                plt.close()
        #         pickle.dump(fig, open(class_name+"/"+filename+".pkl", 'wb'))
    #
    # fig.show()

from simitate import trajectory_loader
from simitate_dataset.simitate_dataset import SimitateTrajectoriesDataset

def create_test_train_split_simitate(folder, split=0.8):
    """
    This method will create a test train split by taking the fist <split> amount
    of files per class for training and the remainder for testing.
    The method works in place! All files are moved in their corresponding split.

    A folder structure like this is expected:

    | simitate
    |---- bring
    |------- <class_images>
    |---- circle
    |------- <class_images>

    After running the method it results in:

    | simitate
    |-- test
    |---- bring
    |------- <class_images>
    |---- circle
    |------- <class_images>
    |-- train
    |---- bring
    |------- <class_images>
    |---- circle
    |------- <class_images>

    :folder: -- folder where the class images are located
    :split: Amount of train / test images. 0.5 means half of the images are used for training
            and the remainder for testing, 0.8 describes a 80/20 split (default 0.5)
    """
    classes = helpers.skeleton_helpers.get_sorted_files_in_folder(folder)
    for c in tqdm(classes):
    #     print (os.fsdecode(c))
        current_class_folder = f"{os.fsdecode(folder)}/{os.fsdecode(c)}"
        files_in_class = helpers.skeleton_helpers.get_sorted_files_in_folder(current_class_folder)
        train_length = int(len(files_in_class)*split)
        train_files = files_in_class[:train_length]
        test_files = files_in_class[train_length:]
        for f in train_files:
            dest_folder = f"{os.fsdecode(folder)}/train/{os.fsdecode(c)}"
            helpers.skeleton_helpers.mk_dest_dir(dest_folder)
            os.rename(f"{current_class_folder}/{os.fsdecode(f)}",
                      f"{dest_folder}/{os.fsdecode(f)}")
        for f in test_files:
            dest_folder = f"{os.fsdecode(folder)}/test/{os.fsdecode(c)}"
            helpers.skeleton_helpers.mk_dest_dir(dest_folder)
            os.rename(f"{current_class_folder}/{os.fsdecode(f)}",
                      f"{dest_folder}/{os.fsdecode(f)}")
        os.rmdir(current_class_folder)

color_map = helpers.skeleton_helpers.generate_color_map(50*3)



def extract_ntu(input_dataset_folder, dataset_folder, max_show=99999999, attention=False, overwrite_if_existing=True, approach="mpl", prefix="", scale_x = 1, scale_y =1, scale_amp=20):
    train_subjects = helpers.skeleton_helpers.get_ntu_cross_subject_train_subjects()
    files = helpers.skeleton_helpers.get_sorted_files_in_folder(input_dataset_folder)

    for i, file in tqdm(enumerate(files), total=len(files)):
        filename = os.fsdecode(file)
#         print(str(i)+"/"+str(len(files)), filename[:1], filename)
        if filename.endswith(".skeleton"):
    #         try:
                skeletons = helpers.skeleton_helpers.load_skeletons(input_dataset_folder+"/"+filename)
                if len(skeletons) == 0:
                    print("Warining: No skeletons found")
                    continue
                if len(skeletons) > 1:
                    skeleton_data = np.concatenate((skeletons[0], skeletons[1]), axis=0)
                else:
                    skeleton_data = skeletons[0]
#                 print(skeleton_data.shape)
                experiment_string = get_experiment_string(skeleton_data, offset=skeleton_data.var(), approach_id=10, size=1, attention=attention, filter_percentage=0.0)

#                 subject = filename[:4]
                subject = filename[8:12]
                class_name = filename[16:16+4]

                # sort into respective folder
                set_cat = helpers.skeleton_helpers.get_test_train_ntu(filename, "cross_subject")
                dest_folder = dataset_folder+experiment_string+"/"+set_cat+"/"+class_name
                helpers.skeleton_helpers.mk_dest_dir(dest_folder)

#                 print(class_name, subject,set_cat, dest_folder)
                dest_filename = dest_folder+"/"+str(prefix)+filename+".png"
                if not os.path.isfile(dest_filename) or overwrite_if_existing:
#                     print(skeleton_data.shape)

                    if approach == "cv":
                        fig = plot_skeleton_data_cv(skeleton_data, offset=skeleton_data.var(), approach_id=10, size=1, attention=attention, filter_percentage=0.3, scale_x = scale_x, scale_y = scale_y, scale_amp=scale_amp)
                        cv2.imwrite(dest_filename, fig)
                        plt.imshow(fig, interpolation='nearest')
                    else:
                        fig = plot_skeleton_data(skeleton_data, offset=skeleton_data.var(), approach_id=10, size=1, attention=attention, filter_percentage=0.0)
                        fig.savefig(dest_filename)
                else:
                    print("File existing, skipping to save time, set overwrite_if_existing to True if you want to regenerate")
#                 fig.savefig("skeleton_representation.svg")
    #             fig.savefig(filename+".png")
                if max_show > 60:
                    plt.close()
    #         except Exception as e:
    #             print("Error", e)
        if i > max_show:
            break

def plot_skeleton_data_cv(skeleton_data, size=5, offset=False, approach_id=1, alpha=0.2, attention=False, filter_percentage=0.5, scale_x = 1, scale_y =1, scale_amp=20):
#     scale_x = 2
#     scale_y = 2
#     scale_amp = 30
    image = np.zeros((skeleton_data.shape[0]*10*scale_x,skeleton_data.shape[2]*scale_y,3), np.uint8)
    if attention:
        skeleton_data = filter_attention(skeleton_data, filter_percentage)
#         print("filtered", skeleton_data.shape)
    sum_max = 0
    for joint_index, joint in enumerate(skeleton_data):
        for axis_index, axis in enumerate(joint):

            if (max(axis) - min(axis)) < 0.001:
#                 print("skip")
                continue
            minimum = min(axis)
            maximum = max(axis)
            sum_max += maximum
#             print(maximum)
            for i in range(1,len(axis)-1):
                try:
                    off_x = (joint_index*5)
                    val = int((axis[i]*scale_amp)+off_x)
                    val1 = int((axis[i+1]* scale_amp)+off_x)
    #                 print(val, val1, color_map[joint_index])
                    color = color_map[joint_index*3]*255
                    color[:] *= min(alpha + (i / len(axis)), 1.0)
#                     print(color)

                    cv2.line(image, (i*scale_y, val*scale_x), ((i+1)*scale_y, val1*scale_x), color , 1)
#                     cv2.circle(image, (i, val), 1, color, thickness=1, lineType=8, shift=0)
#                     image[val,i] = color[:3]
                except Exception as e:
#                     print(e)
                    continue

    return image

def get_aril_dataset():
    dataset_name = "ARIL"
    dataset_folder = os.environ["DATASET_FOLDER"]+"/"+dataset_name
    data = sio.loadmat(dataset_folder+'/train_data_split_amp.mat')
    data_test = sio.loadmat(dataset_folder+'/test_data_split_amp.mat')
    train_split = data["train_data"]
    test_split = data_test["test_data"]
    train_classes = data['train_activity_label']
    test_classes = data_test['test_activity_label']

#     train_split.shape, test_split.shape
#     train_classes.shape, test_classes.shape

    color_map = color_map = helpers.skeleton_helpers.generate_color_map(52) #  52 bands
    return dataset_name, dataset_folder, train_split, train_classes, test_classes, test_split, color_map

def plot_wifi_signal(data, classes, dest, max_show=-1, show=False, save=True ,save_svg=False):
    for i, wifi_signal in tqdm(enumerate(data), total = len(data)):
        if i > max_show-1 and max_show is not -1:
            break
        fig = plt.figure(figsize=(10,10))

        ax = fig.add_subplot(frameon=False)
        ax.axis("off")
        plt.box(False)
        fig.tight_layout(pad=0)
        # To remove the huge white borders
        ax.margins(0)
        label = classes[i][0]
#         print(label[0])
        for j in range(len(wifi_signal)):
            ax.plot(range(len(wifi_signal[j])), wifi_signal[j], "-", linewidth=1, c=color_map[j]);



        if save:
            dest_folder = str(dest)+"/"+str(label)
#             print(dest_folder)
            os.makedirs(dest_folder, exist_ok=True)
            fig.savefig(dest_folder+"/"+str(i).zfill(5)+".png")
            if save_svg:
                dest_folder_svg = "exported_svg/"+dest_folder+"/"
                os.makedirs(dest_folder_svg, exist_ok=True)
                dest_filename_svg = dest_folder_svg+str(i).zfill(5)+".svg"
                fig.savefig(dest_filename_svg)
        if not show:
            plt.close()

# print(skeleton_data.shape, len(skeleton_data))
def animate_all_ARIL(data):
    for i, signals in enumerate(data):
        signals = data[i]
        a = SignalAnimation(signals, clear_frames=True)
        #a.animate()
        #x = a.animate_html5()

        dest_name = str(i).zfill(5)+".mp4"
        print("Processing %s" % (dest_name))
        a.save_as_mp4(dest_name)

def generate(mappings, max_show = 10, overwrite_if_existing=False, folder_per_class=False):
    cnt = 0
    image_files = []
    image_labels = []
    for source_folder, dest_folder in mappings.items():
        try:
#             print(source_folder, dest_folder)
            files = sorted(os.listdir(source_folder))
            if not folder_per_class:
                os.makedirs(dest_folder, exist_ok=True)
            else:
                basename = os.path.basename(dest_folder)
#           print(basename)
            for file in files:
                try:

                    # in scene 3 classes are extra
                    label = file[:-4] + ("_desk" if basename.find("scene3") > -1 else "")
#                     basename = ""
                    if folder_per_class:
                        # restructure the folder structure such that it's working with the pytorch imagedataloader

                        dest_folder = os.path.dirname(dest_folder)+"/"+label
                        os.makedirs(dest_folder, exist_ok=True)
#                         print(dest_folder)

                    dest_file = dest_folder+"/"+basename+file[:-4]+".png"

                    # this is needed as the desk classes are classified as extra classes,
                    # this is for using_phone_desk, talking_on_phone_desk
                    if dest_file.find("scene3") > -1:
                        label +="_desk"
                    image_labels.append(label)
#                     print(dest_file, label)

                    if overwrite_if_existing:
                        file_path = source_folder+"/"+file
                        df = pd.read_csv(file_path, header=None)
                        data = df.to_numpy()
                        data = data[:,1:4].transpose()
#                         return data
                        fig = plot_skeleton_data(data)
#                         fig = plt.figure(figsize=(5,5))
                        #   fig.title(filename)
#                         ax = fig.add_subplot(frameon=False)
#                         ax.axis("off")
            #             print(file_path)

#                         for signal in data.transpose()[1:]:
#                             plt.plot(signal,alpha=0.5)

                        print(dest_file)
                        plt.savefig(dest_file[:-4]+".png")
                        cnt += 1
                        if cnt >= max_show:
                            plt.close()
                    image_files.append(os.path.relpath(dest_file, dest_file+("../"*7)))
                except Exception as e:
                    print(e) #file_path)
        except Exception as e:
            print(e)
    print("%d representations are generated." % (cnt))
    return image_files, image_labels
